---
title: Check robots.txt file of a website for errors and typos
author: adityakane
date: 2010-05-07
url: /check-robots-txt-file-of-a-website-for-errors-and-typos/
views:
  - 353
dsq_thread_id:
  - 2947110117
categories:
  - Reviews
tags:
  - Domain
  - Interesting Links
  - Search
  - Search Engines
---
If you own a website and are obsessed with your website being search engine friendly you will probably be aware of a file called robots.txt which often has the site-map to your website. This site-map is immediately picked up by search engines web crawlers which is how search engines end up indexing billions of web pages.

### **What does robots.txt file do?**

  * A web robot or web crawler which first visits a website it looks up for the robots.txt files. For example when a search crawler looks up ***http://devilsworkshop.org*** it will look up for ***http://devilsworkshop.org/robots.txt.***
  * This **robots.txt** actually allows and disallows a search engine to look up certain directories of a domain. For instance if you website has hosted a wiki you do not want to be accessible for search engines to look up, then that directory has to be excluded from looking up by a search engine.

This is why is it necessary to check **robots.txt** file for typos and errors which might defeat the purpose of excluding certain directories on your website from being looked up.

<p style="text-align: center;">
  <a rel="attachment wp-att-24639" href="http://devilsworkshop.org/check-robots-txt-file-of-a-website-for-errors-and-typos/robots_checker/"><img class="aligncenter size-full wp-image-24639" style="border: 1px solid teal;" title="robots_checker" src="http://cdn.devilsworkshop.org/files/2010/05/robots_checker.png" alt="" width="550" height="301" /></a>
</p>

<p style="text-align: center;">
  <h3>
    <strong>About <a href="http://www.frobee.com/robots-txt-check" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://www.frobee.com/robots-txt-check', 'Robots.txt checker']);" >Robots.txt checker</a></strong>
  </h3>
  
  <ul>
    <li>
      The website allows you to enter any URL and check the <strong>robots.txt</strong> file. This scan is usually looks up errors based on what is disallowed.
    </li>
    <li>
      It also shows up warning for any matches what might be misunderstood or ignored by search engine crawlers.
    </li>
  </ul>
  
  <p>
    This is not really something that I would recommend webmasters to obsess over as usually most <strong>robots.txt</strong> of many websites are similar. For example you will see identical robots.txt files for almost all generic blogs which are hosted with WordPress. This tool will be useful mainly if you have many directories which you want not to be looked up by web bots.
  </p>
  
  <p>
    You might like to look up <a title="how to look up sites and do manual web crawling" href="http://devilsworkshop.org/do-manual-web-crawling-and-look-up-site-maps/">how to look up sites and do manual web crawling</a>.
  </p>
  
  <p>
    Do try out this web service and let me know what you views on it by dropping in a comment.
  </p>
  
  <p>
    <strong>Link: </strong><a href="http://www.frobee.com/robots-txt-check" onclick="_gaq.push(['_trackEvent', 'outbound-article', 'http://www.frobee.com/robots-txt-check', 'Robots.txt Checker']);" >Robots.txt Checker</a>
  </p>
